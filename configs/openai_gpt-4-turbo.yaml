# Configuration for OpenAI's gpt-4-turbo model

provider: "openai"
model: "gpt-4-turbo"

endpoint: "https://api.openai.com/v1/chat/completions"

description: "The latest GPT-4 Turbo model with vision capabilities. Vision requests have a separate rate limit. For both vision and text requests, the model supports a 128k context window."

required_fields:
  - "messages"

parameters:
  temperature:
    type: "float"
    default: 0.7
    description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."
  max_tokens:
    type: "integer"
    default: 4096
    description: "The maximum number of tokens that can be generated in the chat completion."